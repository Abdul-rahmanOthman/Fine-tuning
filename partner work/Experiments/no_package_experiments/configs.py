configuration1 = {
  'positive_reward' : 10,
  'negative_reward' : -13,
  'asking_reward' : -3,
  'policy_lr': 0.0037,
  'value_lr': 0.001,
  'gamma': 0.92,
  'vf_coeff': 0.1879601677,
  'entropy_coefficient': 0.06057,
  'policy_clip': 0.2375,
  'gae_lambda': 0.814,
  'batch_size': 128,
  'N_steps' : 256,
  'n_epochs': 10,
  'decay': 0.97
}


